{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## FPF Gain approximation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text',usetex = True)\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import ridge\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to generate samples from a multi-dimensional 1d- Gaussian mixture $\\times$  (d-1) independnt Gaussian distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(N, mu, sigma_b, w, dim,  sigma = None):\n",
    "    Xi  = np.zeros((N,dim))\n",
    "    for i in range(N):\n",
    "        if np.random.uniform() <= w[0]:\n",
    "            Xi[i,0] = mu[0]  + sigma_b[0] * np.random.normal()\n",
    "        else:\n",
    "            Xi[i,0]  = mu[1]  + sigma_b[1] * np.random.normal()\n",
    "        for d in range(1, dim):\n",
    "            Xi[i,d] = sigma * np.random.normal()\n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute the mean square error in gain function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(K_exact, K_approx, p):\n",
    "    N = len(K_exact)\n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    mse = (1/N) * np.linalg.norm(K_exact - K_approx)**2\n",
    "    # mse2 = np.sum(((K_exact - K_approx)**2) *np.concatenate(p_vec(Xi)))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different gain approximation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using optimal RKHS method  \n",
    "uses the extended representer theorem in - https://www.sciencedirect.com/science/article/pii/S0377042707004657?via%3Dihub\n",
    "#### Algorithm\n",
    "\\begin{equation}\n",
    "\\text{K}(x) = \\sum_{i=1}^N \\Bigl[ \\beta^0_i K(x^i,x) + \\beta^1_i \\frac{\\partial K} {\\partial x}(x^i,x) \\Bigr]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\beta ^* = M^{-1} b\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\\text{where,\n",
    "\t}\n",
    "\t\\quad\n",
    "\tM & := \\frac{1}{N} \\left[\\begin{array}{c} M_y\\\\ \\hline M_{xy} \\end{array}\\right] [ M_x \\,| M_{xy}] + \\lambda  \\left[\n",
    "\t\\begin{array}{c|c}\n",
    "\tM_0 & M_y \\\\\n",
    "\t\\hline\n",
    "\tM_x & M_{xy}\n",
    "\t\\end{array}\n",
    "\t\\right] \\\\\n",
    "\tb & :=  \\frac{1}{N} \\left[ \\begin{array}{c} M_0 \\\\ \\hline M_x \\end{array}\\right] \\tilde{c}\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{aligned}\n",
    "M_0(i,j) &:= K(x^i,x^j)\n",
    "\\quad\n",
    "& M_x(i,j) &:= \\frac{\\partial K}{\\partial x}(x^i,x^j)\n",
    "\\\\\n",
    "M_y(i,j) &:= \\frac{\\partial K}{\\partial y}(x^i,x^j)\n",
    "\\quad\n",
    "& M_{xy}(i,j) &:= \\frac{\\partial^2 K}{\\partial x \\partial y}(x^i,x^j).\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_2N(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    Ker_x = np.array(np.zeros((N,N)))\n",
    "    Ker_xy = np.array(np.zeros((N,N)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j] = -(Xi[i]-Xi[j]) * Ker[i,j] / (2 * epsilon)\n",
    "            Ker_xy[i,j] = -(((Xi[i] - Xi[j])**2) / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon) # Negative of the second Gaussian derivative, as this is K_xy and not K_x2\n",
    "    \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    # Constructing block matrices for future use\n",
    "    # K_big      = [ Ker Ker_x ; Ker_x' Ker_x_y];\n",
    "    # K_thin_yxy = [ Ker_x ; Ker_x_y]; \n",
    "    # K_thin_x   = [ Ker ; Ker_x'];\n",
    "    K_big      = np.concatenate((np.concatenate((Ker,np.transpose(Ker_x)),axis = 1), np.concatenate((Ker_x, Ker_xy),axis =1)))\n",
    "    K_thin_yxy = np.concatenate((np.transpose(Ker_x), Ker_xy))\n",
    "    K_thin_xxy = np.concatenate((Ker_x,Ker_xy), axis = 1)\n",
    "    K_thin_x   = np.concatenate((Ker, Ker_x))\n",
    "    \n",
    "    # b used in the extended representer theorem algorithm - searching over all of the Hilbert space H\n",
    "    b_2m        = (1/N) * np.dot(K_thin_x, Y)\n",
    "    M_2m        = Lambda * K_big + (1/N) * np.matmul(K_thin_yxy, np.transpose(K_thin_yxy))\n",
    "    # M_2m        = Lambda * K_big + (1/N) * np.matmul(K_thin_yxy, K_thin_xxy)\n",
    "    beta_2m     = np.linalg.solve(M_2m, b_2m)   \n",
    "    \n",
    "    K = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + beta_2m[j] * Ker_x[i,j] + beta_2m[N+j] * Ker_xy[i,j]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,0],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,0], 'b*')\n",
    "        plt.plot(Xi, Ker_xy[:,0],'k*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using subspace RKHS method  \n",
    "uses normal representer theorem, obtains optimal solution on a subspace of RKHS.\n",
    "#### Algorithm\n",
    "\\begin{equation}\n",
    "\\text{K}(x) = \\sum_{i=1}^N \\beta^*_i \\frac{\\partial K}{\\partial x} (x^i,x)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\beta  := M^{-1} b   \\,,\n",
    "\\end{equation}\n",
    "where $ M := N^{-1} M_y M_x + \\lambda M_0$ and $ b := N^{-1} M_0 \\, \\tilde{c}  $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_N(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    Ker_x = np.array(np.zeros((N,N)))\n",
    "    Ker_xy = np.array(np.zeros((N,N)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j] = -(Xi[i]-Xi[j]) * Ker[i,j] / (2 * epsilon)\n",
    "    \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    b_m = (1/ N) * np.dot(Ker,Y)\n",
    "    M_m = Lambda * Ker + (1/ N) * np.matmul(Ker_x, Ker_x.transpose())\n",
    "    beta_m = np.linalg.solve(M_m,b_m)\n",
    "    \n",
    "    K = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + beta_m[j] * Ker_x[i,j]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,100],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,100], 'b*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute the exact FPF gain by numerical integration\n",
    "#### Algorithm\n",
    "\\begin{equation} \n",
    "\\text{K}(x) =  - \\frac{1}{p(x)} \\int_{-\\infty}^{x} (c(y) - \\hat{c}) p(y) dy\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_exact(Xi, c, p):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    integral = np.zeros(N)\n",
    "    \n",
    "    step = 0.01\n",
    "    xmax = max(mu) + 10\n",
    "    \n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    c_vec = lambdify(x, c, 'numpy')\n",
    "    cp    = lambdify(x, c*p, 'numpy')\n",
    "    c_hat = integrate.quad(cp, -np.inf, np.inf)[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        integral[i] = 0\n",
    "        for xj in np.arange(Xi[i], xmax + 10,  step):\n",
    "            integral[i] = integral[i] + p_vec(xj) * ( c_vec(xj) - c_hat) * step\n",
    "        K[i] = integral[i]/ p_vec(Xi[i])\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using scipy.integrate.quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_num_integrate(Xi, c, p):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    integral = np.zeros(N)\n",
    "     \n",
    "    if Xi.shape[1] == 1:\n",
    "        p_x = lambdify(x, p, 'numpy')\n",
    "        cp_x  = lambdify(x, c*p, 'numpy')\n",
    "        c_hat = integrate.quad(cp_x, -np.inf, np.inf)[0]\n",
    "        integrand_x = lambdify(x, p * (c - c_hat) , 'numpy')\n",
    "        integrand = lambda x: integrand_x(x)\n",
    "    else:\n",
    "        p_x = lambdify(x[0], p, 'numpy')\n",
    "        cp_x  = lambdify(x[0], c*p, 'numpy')\n",
    "        c_hat = integrate.quad(cp_x, -np.inf, np.inf)[0]\n",
    "        integrand_x = lambdify(x[0], p * (c - c_hat) , 'numpy')\n",
    "        integrand = lambda x: integrand_x(x)\n",
    "        print(integrand)\n",
    "   \n",
    "    for i in range(N):\n",
    "        if Xi.shape[1] == 1:\n",
    "            integral[i] = integrate.quad( integrand, -np.inf, Xi[i])[0]\n",
    "            K[i] = - integral[i]/ p_x(Xi[i])\n",
    "        else:\n",
    "            integral[i] = integrate.quad( integrand, -np.inf, Xi[i,0])[0]\n",
    "            K[i] = - integral[i]/ p_x(Xi[i,0])\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using Markov kernel approx. method -\n",
    "Based on the Markov semigroup approximation method in https://arxiv.org/pdf/1902.07263.pdf\n",
    "#### Algorithm  \n",
    "1.Calculate $g_{ij} = \\exp(-|X^i - X^j|^2/ 4\\epsilon)$ for $i,j = 1$ to $N$  \n",
    "2.Calculate $k_{ij} = \\frac{g_{ij}}{\\sqrt{\\sum_l g_{il}}\\sqrt{\\sum_l g_{jl}}}$  \n",
    "3.Calculate $d_i = \\sum_j k_{ij}$  \n",
    "4.Calculate $\\text{T}_{ij} = \\frac{k_{ij}}{d_i}$  \n",
    "5.Calculate $\\pi_i = \\frac{d_i}{\\sum_j d_j}$  \n",
    "6.Calculate $ \\hat{h} = \\sum_{i = 1}^N \\pi_i h(X^i)$  \n",
    "7.Until convergence, $\\Phi_i = \\sum_{j=1}^N \\text{T}_{ij} \\Phi_j + \\epsilon (h - \\hat{h})$  \n",
    "8.Calculate $r_i = \\Phi_i + \\epsilon h_i$  \n",
    "9.Calculate $s_{ij} = \\frac{1}{2\\epsilon} \\text{T}_{ij} (r_j - \\sum_{k=1}^N \\text{T}_{ik} r_k)$  \n",
    "10.Calulate $\\text{K}_i  = \\sum_j s_{ij} X^j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_coif(Xi, C, epsilon, Phi, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    k = np.zeros((N,N))\n",
    "    K = np.zeros(N)\n",
    "    d = np.zeros(N)\n",
    "    T = np.zeros((N,N))\n",
    "    Phi = np.zeros(N)\n",
    "    sum_term = np.zeros(N)\n",
    "    max_diff = 1\n",
    "    \n",
    "    No_iterations = 50000\n",
    "    iterations = 1\n",
    "    \n",
    "    g = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            k[i,j] = g[i,j] / (np.sqrt( (1/N) * sum(g[i,:])) * np.sqrt( (1/N)* sum(g[j,:])))\n",
    "        d[i] = np.sum(k[i,:])\n",
    "        T[i,:] = np.divide(k[i,:], np.sum(k[i,:]))\n",
    "    pi = np.divide(d, np.sum(d))\n",
    "    C_hat = np.dot(pi, C)\n",
    "                      \n",
    "    while((max_diff > 1e-2) & ( iterations < No_iterations )):\n",
    "        Phi_new = np.matmul(T,Phi) + (epsilon * np.concatenate(C - C_hat)).transpose() \n",
    "        max_diff = max(Phi_new - Phi) - min(Phi_new - Phi)\n",
    "        Phi  = Phi_new\n",
    "        iterations += 1\n",
    "    \n",
    "    r = Phi + epsilon * np.concatenate(C)\n",
    "    for i in range(N):\n",
    "        sum_term[i] = np.dot( T[i,:], r)\n",
    "        K[i] = 0\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + (1/ (2 * epsilon)) * T[i,j] * (r[j] - sum_term[i]) * Xi[j]                                  \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, g[1,:], 'r*')\n",
    "        plt.show()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly older version of Markov kernel approximation - from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7799105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_coif_old(Xi, C, epsilon, Phi, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    k = np.zeros((N,N))\n",
    "    K = np.zeros(N)\n",
    "    d = np.zeros(N)\n",
    "    T = np.zeros((N,N))\n",
    "    Phi = np.zeros(N)\n",
    "    sum_term = np.zeros(N)\n",
    "    max_diff = 1\n",
    "    \n",
    "    No_iterations = 50000\n",
    "    iterations = 1\n",
    "    \n",
    "    g = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            k[i,j] = g[i,j] / (np.sqrt( (1/N) * sum(g[i,:])) * np.sqrt( (1/N)* sum(g[j,:])))\n",
    "        d[i] = np.sum(k[i,:])\n",
    "        T[i,:] = np.divide(k[i,:], np.sum(k[i,:]))\n",
    "                      \n",
    "    while((max_diff > 1e-2) & ( iterations < No_iterations )):\n",
    "        Phi_new = np.matmul(T,Phi) + (epsilon * np.concatenate(C)).transpose() \n",
    "        max_diff = max(Phi_new - Phi) - min(Phi_new - Phi)\n",
    "        Phi  = Phi_new\n",
    "        iterations += 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        sum_term[i] = np.dot( T[i,:], Xi)\n",
    "        K[i] = 0\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + (1/ (2 * epsilon)) * T[i,j] * Phi[j,] * (Xi[j] - sum_term[i])   \n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, g[1,:], 'r*')\n",
    "        plt.show()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using RKHS OM method - Adds a Lagrangian parameter $\\mu$ to make use of the constant gain approximation\n",
    "#### Algorithm\n",
    "$\\beta^*$ obtained by solving the set of linear equations\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "0  &=  2 \\Bigl(  \\frac{1}{N}  \\sum_{k=1}^d M_{x_k}^T M_{x_k}   +  \\lambda M_0 \\Bigr) \\beta ^* + \\frac{ \\kappa \\mu ^*}{N}+  \\frac{2}{N} \\Bigl( \\kappa \\text{K}^*  -   M_0 \\tilde{c} \\Bigr)  \\\\\n",
    "0  & = \\kappa^{T} \\beta^*\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_om(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    Ker_x = np.array(np.zeros((N,N)))\n",
    "    Ker_xy = np.array(np.zeros((N,N)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j] = -(Xi[i]-Xi[j]) * Ker[i,j] / (2 * epsilon)\n",
    "            Ker_xy[i,j] = (((Xi[i] - Xi[j])**2) / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon)\n",
    "    Ker_x_ones = np.dot(np.ones((1,N)), Ker_x)\n",
    "   \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    K_hat = np.mean(Y * Xi)\n",
    "    \n",
    "    b_m = (1/ N) * np.dot(Ker,Y) - (1/ N) * np.transpose(Ker_x_ones) * K_hat \n",
    "    b_m = np.append(b_m, np.zeros((1,1)))\n",
    "    \n",
    "    M_m = Lambda * Ker + (1 / N) * np.matmul(Ker_x, Ker_x.transpose()) \n",
    "    M_m = np.vstack((M_m, (1/N) * Ker_x_ones))\n",
    "    M_m = np.hstack((M_m, np.transpose(np.append(Ker_x_ones,np.zeros((1,1)))).reshape(len(M_m),1)))\n",
    "    \n",
    "    beta_m = np.linalg.solve(M_m,b_m)\n",
    "    \n",
    "    K = np.zeros(N)\n",
    "    K.fill(K_hat)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + beta_m[j] * Ker_x[i,j]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,0],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,0], 'b*')\n",
    "        plt.plot(Xi, Ker_xy[:,0],'k*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code\n",
    "#### Defines a 2-component Gaussian mixture density $p$, generates samples from $p$ and passes to the various gain approximation functions, that return the gain vectors. If exact flag is set, the exact gain is computed via numerical integration and is used to compute mean-squared error of each of the approximations.  \n",
    "Can change parameters like - no. of independent trials, no. of particles $N$, dimensionality of the system $d$ etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "(200, 1)\n",
      "Time taken 0.3774483931274517\n",
      "Time taken 3.1341593014049067\n",
      "Time taken 0.6472903527578637\n",
      "\n",
      "\n",
      "MSE for Markov kernel approx 1.0069515978423196\n",
      "MSE for RKHS 2N 1.0724238086795297\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Flags to be set to choose which methods to compare\n",
    "    exact  = 1      # Computes the exact gain and plots \n",
    "    coif   = 1      # Computes gain using Coifman kernel method\n",
    "    rkhs_N = 0      # Computes gain using subspace of RKHS\n",
    "    rkhs_2N= 1      # Computes optimal gain using RKHS \n",
    "    om     = 0      # Computes gain using RKHS enforcing constant gain constraint\n",
    "    memory = 0      # Computes gain using RKHS with a memory parameter for previous gain\n",
    "    om_mem = 0      # Computes gain using const gain approx and a memory parameter for previous gain\n",
    "    \n",
    "    coif_old = 0   # Computes old implementation of Coifman kernel approx. \n",
    "    const  = 0      # Computes the constant gain approximation\n",
    "    kalman = 0      # Runs Kalman Filter for comparison\n",
    "    sis    = 0      # Runs Sequential Importance Sampling Particle Filter \n",
    "\n",
    "    # Run parameters\n",
    "    No_runs = 1\n",
    "    \n",
    "    # FPF parameters - No. of particles\n",
    "    N = 200\n",
    "    \n",
    "    # System parameters\n",
    "    x = Symbol('x')\n",
    "    dim = 1     # dimension of the system\n",
    "    c = x       # Observation function\n",
    "    c_x = lambdify(x, c, 'numpy')\n",
    "        \n",
    "    # Parameters of the prior density p(0) - 2 component Gaussian mixture density\n",
    "    m = 2      # No of components in the Gaussian mixture\n",
    "    sigma = [0.4, 0.4]\n",
    "    mu  = [-1, 1]\n",
    "    w   = [0.5, 0.5]\n",
    "    w[-1] = 1 - sum(w[:-1])\n",
    "    p = 0\n",
    "    mu_eq = 0  # Equivalent mean of the density p\n",
    "    for m in range(len(w)):\n",
    "        p = p + w[m] * (1/ np.sqrt(2 * math.pi * sigma[m]**2))* exp(-(x - mu[m])**2/ (2* sigma[m]**2))\n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    \n",
    "    mse_coif = np.zeros(No_runs)\n",
    "    mse_rkhs_N = np.zeros(No_runs)\n",
    "    mse_rkhs_2N = np.zeros(No_runs)\n",
    "    mse_om   = np.zeros(No_runs)\n",
    "    mse_coif_old = np.zeros(No_runs)\n",
    "    for run in range(No_runs):\n",
    "        print('Run ',run)\n",
    "        Xi  = get_samples(N, mu, sigma, w, dim)\n",
    "        if dim == 1:\n",
    "            Xi = np.sort(Xi,kind = 'mergesort')\n",
    "        C   = c_x(Xi)\n",
    "        print(C.shape)\n",
    "# To check consistency with Matlab code output - using the same samples \n",
    "#         Xi = np.loadtxt('Xi.txt')\n",
    "#         Xi = np.sort(Xi,kind = 'mergesort')\n",
    "#         Xi = np.reshape(Xi,(-1,1))\n",
    "#         plt.figure()\n",
    "#         sns.distplot(Xi)\n",
    "#         plt.show()\n",
    "\n",
    "        if exact == 1:\n",
    "            # c_hat = mu_eq   # True only for c = x, linear function          \n",
    "            # K_exact  = gain_exact(Xi, c, p)   # Manual numerical integration\n",
    "            K_exact =  gain_num_integrate(Xi, c, p)  # Uses scipy.integrate function\n",
    "\n",
    "        if coif ==1:\n",
    "            eps_coif = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif = gain_coif(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif[run] = mean_squared_error(K_exact, K_coif, p)\n",
    "\n",
    "        if rkhs_N == 1:\n",
    "            eps_rkhs_N = 0.1\n",
    "            Lambda_rkhs_N = 1e-3\n",
    "            K_rkhs_N = gain_rkhs_N(Xi, C, eps_rkhs_N, Lambda_rkhs_N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_N[run] = mean_squared_error(K_exact, K_rkhs_N, p)\n",
    "\n",
    "        if rkhs_2N == 1:\n",
    "            eps_rkhs_2N = 0.1\n",
    "            Lambda_rkhs_2N = 1e-3\n",
    "            K_rkhs_2N = gain_rkhs_2N(Xi, C, eps_rkhs_2N, Lambda_rkhs_2N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_2N[run] = mean_squared_error(K_exact, K_rkhs_2N, p)\n",
    "\n",
    "        if om == 1:\n",
    "            eps_om = 0.1\n",
    "            Lambda_om = 1e-3\n",
    "            K_om = gain_rkhs_om(Xi, C, eps_om, Lambda_om, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_om[run] = mean_squared_error(K_exact, K_om, p)\n",
    "                \n",
    "        if coif_old == 1:\n",
    "            eps_coif_old = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif_old = gain_coif_old(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif_old[run] = mean_squared_error(K_exact, K_coif_old, p)\n",
    "         \n",
    "    print('\\n')\n",
    "    if exact == 1 & coif == 1:\n",
    "        print('MSE for Markov kernel approx', np.mean(mse_coif))\n",
    "    if exact == 1 & rkhs_N == 1:\n",
    "        print('MSE for RKHS N', np.mean(mse_rkhs_N))\n",
    "    if exact == 1 & rkhs_2N == 1:\n",
    "        print('MSE for RKHS 2N', np.mean(mse_rkhs_2N))\n",
    "    if exact == 1 & om == 1:\n",
    "        print('MSE for RKHS OM', np.mean(mse_om))\n",
    "    if exact == 1 & coif_old == 1:\n",
    "        print('MSE for old Markov kernel', np.mean(mse_coif_old))\n",
    "    \n",
    "    ### Displaying the plots\n",
    "    marker_size  = 3\n",
    "    plt.rc('text', usetex=True)\n",
    "    fig,ax1 = plt.subplots()\n",
    "    if exact == 1:\n",
    "        ax1.plot(Xi, K_exact, 'b.', markersize = marker_size, label ='Exact gain')\n",
    "        # ax1.plot(Xi, K_num_int, 'k^', markersize = marker_size, label ='Num int. gain')\n",
    "    if rkhs_N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_N, 'r.', markersize = marker_size, label = 'RKHS approx. N')\n",
    "    if rkhs_2N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_2N, 'c.', markersize = marker_size, label = 'RKHS approx. 2N')\n",
    "    if coif == 1:\n",
    "        ax1.plot(Xi, K_coif, 'g.', markersize = marker_size, label ='Markov kernel approx.')\n",
    "    if om == 1:\n",
    "        ax1.plot(Xi, K_om, 'm.', markersize = marker_size, label = 'RKHS OM')\n",
    "    if coif_old == 1:\n",
    "        ax1.plot(Xi, K_coif_old, 'y.', markersize = marker_size, label ='Old Markov kernel')\n",
    "    ax2 =ax1.twinx()\n",
    "    ax2.plot(np.arange(-2,2,0.01), p_vec(np.arange(-2,2,0.01)),'k.-', markersize =1, label = r'$\\rho(x)$')\n",
    "    ax2.set_ylabel(r'$\\rho(x)$')\n",
    "    ax2.legend(loc=1)\n",
    "    ax1.set_xlabel('Particle Locations')\n",
    "    ax1.set_ylabel('Gain $K(x)$')\n",
    "    ax1.legend()\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-dimensional example in section 5.1  - https://arxiv.org/pdf/1902.07263.pdf  \n",
    "\\begin{equation}\n",
    "\\rho(x) = \\rho_B(x_1) \\prod_{n=2}^d \\rho_G(x_n), \\qquad \\text{for } x = (x_1,x_2, \\cdots, x_d) \\in \\mathbb{R}^d \n",
    "\\end{equation}\n",
    "Here, $\\rho_B$ is $\\frac{1}{2} \\mathcal{N}(-1, \\sigma^2) + \\frac{1}{2}\\mathcal{N}(+1,\\sigma^2)$ is bimodal distribution  \n",
    "$\\rho_G$ is Gaussian distribution, $\\mathcal{N}(0,\\sigma^2)$  \n",
    "Observation function, $h(x) = x_1$  \n",
    "Exact gain function, $\\text{K}_{\\text{exact}}(x) = (\\text{K}_{\\text{exact}}(x_1), 0, \\cdots,0)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "<function gain_num_integrate.<locals>.<lambda> at 0x000001E5A0CB8730>\n",
      "Time taken 0.36233136803457455\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-c4327b7e8917>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0meps_coif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mPhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mK_coif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain_coif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_coif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPhi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexact\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mmse_coif\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_coif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-1ba4d93309cd>\u001b[0m in \u001b[0;36mgain_coif\u001b[1;34m(Xi, C, epsilon, Phi, diag)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum_term\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mXi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdiag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Flags to be set to choose which methods to compare\n",
    "    exact  = 1      # Computes the exact gain and plots \n",
    "    coif   = 1      # Computes gain using Coifman kernel method\n",
    "    rkhs_N = 1      # Computes gain using subspace of RKHS\n",
    "    rkhs_2N= 0      # Computes optimal gain using RKHS \n",
    "    om     = 0      # Computes gain using RKHS enforcing constant gain constraint\n",
    "    memory = 0      # Computes gain using RKHS with a memory parameter for previous gain\n",
    "    om_mem = 0      # Computes gain using const gain approx and a memory parameter for previous gain\n",
    "    \n",
    "    coif_old = 1    # Computes old implementation of Coifman kernel approx. \n",
    "    const  = 0      # Computes the constant gain approximation\n",
    "    kalman = 0      # Runs Kalman Filter for comparison\n",
    "    sis    = 0      # Runs Sequential Importance Sampling Particle Filter \n",
    "\n",
    "    # Run parameters\n",
    "    No_runs = 1\n",
    "    \n",
    "    # FPF parameters - No. of particles\n",
    "    N = 200\n",
    "    \n",
    "    # System parameters\n",
    "    dim = 2     # dimension of the system\n",
    "    x = symbols('x0:%d'%dim)\n",
    "    c = x[0]       # Observation function\n",
    "    c_x = lambdify(x, c, 'numpy')\n",
    "        \n",
    "    # Parameters of the prior density \\rho_B - 2 component Gaussian mixture density\n",
    "    m = 2      # No of components in the Gaussian mixture\n",
    "    sigma_b = [0.4472, 0.4472]   # Gives \\sigma^2 = 0.2\n",
    "    mu_b  = [-1, 1]\n",
    "    w_b   = [0.5, 0.5]\n",
    "    w_b[-1] = 1 - sum(w_b[:-1])\n",
    "    p_b = 0\n",
    "    mu_eq = 0  # Equivalent mean of the density p\n",
    "    for m in range(len(w_b)):\n",
    "        p_b = p_b + w_b[m] * (1/ np.sqrt(2 * math.pi * sigma_b[m]**2))* exp(-(x[0] - mu_b[m])**2/ (2* sigma_b[m]**2))\n",
    "    sigma = 0.4472  # Chosen so that \\sigma^2 = 0.2 as in the reference\n",
    "    p = p_b\n",
    "    for d in np.arange(1,dim):\n",
    "        p_g = exp(-x[d])**2/ (2 * sigma**2)\n",
    "        p*= p_g\n",
    "    p_vec = lambdify(x, p_g, 'numpy')\n",
    "    \n",
    "    mse_coif = np.zeros(No_runs)\n",
    "    mse_rkhs_N = np.zeros(No_runs)\n",
    "    mse_rkhs_2N = np.zeros(No_runs)\n",
    "    mse_om   = np.zeros(No_runs)\n",
    "    mse_coif_old = np.zeros(No_runs)\n",
    "    for run in range(No_runs):\n",
    "        print('Run ',run)\n",
    "        Xi  = get_samples(N, mu_b, sigma_b, w_b, dim, sigma)\n",
    "        get_samples\n",
    "        if dim == 1:\n",
    "            Xi = np.sort(Xi,kind = 'mergesort')\n",
    "        C   = np.reshape(c_x(Xi[:,0],Xi[:,1]),(len(Xi),1))\n",
    "        \n",
    "        if exact == 1:\n",
    "         \n",
    "            K_exact = np.zeros((N, dim))\n",
    "            K_exact[:,0]  = gain_num_integrate(Xi, c, p_b)\n",
    "\n",
    "        if coif ==1:\n",
    "            eps_coif = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif = gain_coif(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif[run] = mean_squared_error(K_exact, K_coif, p)\n",
    "\n",
    "        if rkhs_N == 1:\n",
    "            eps_rkhs_N = 0.1\n",
    "            Lambda_rkhs_N = 1e-3\n",
    "            K_rkhs_N = gain_rkhs_N(Xi, C, eps_rkhs_N, Lambda_rkhs_N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_N[run] = mean_squared_error(K_exact, K_rkhs_N, p)\n",
    "\n",
    "        if rkhs_2N == 1:\n",
    "            eps_rkhs_2N = 0.1\n",
    "            Lambda_rkhs_2N = 1e-3\n",
    "            K_rkhs_2N = gain_rkhs_2N(Xi, C, eps_rkhs_2N, Lambda_rkhs_2N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_2N[run] = mean_squared_error(K_exact, K_rkhs_2N, p)\n",
    "\n",
    "        if om == 1:\n",
    "            eps_om = 0.1\n",
    "            Lambda_om = 1e-3\n",
    "            K_om = gain_rkhs_om(Xi, C, eps_om, Lambda_om, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_om[run] = mean_squared_error(K_exact, K_om, p)\n",
    "                \n",
    "        if coif_old == 1:\n",
    "            eps_coif_old = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif_old = gain_coif_old(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif_old[run] = mean_squared_error(K_exact, K_coif_old, p)\n",
    "         \n",
    "    print('\\n')\n",
    "    if exact == 1 & coif == 1:\n",
    "        print('MSE for Markov kernel approx', np.mean(mse_coif))\n",
    "    if exact == 1 & rkhs_N == 1:\n",
    "        print('MSE for RKHS N', np.mean(mse_rkhs_N))\n",
    "    if exact == 1 & rkhs_2N == 1:\n",
    "        print('MSE for RKHS 2N', np.mean(mse_rkhs_2N))\n",
    "    if exact == 1 & om == 1:\n",
    "        print('MSE for RKHS OM', np.mean(mse_om))\n",
    "    if exact == 1 & coif_old == 1:\n",
    "        print('MSE for old Markov kernel', np.mean(mse_coif_old))\n",
    "    \n",
    "    ### Displaying the plots\n",
    "    marker_size  = 3\n",
    "    plt.rc('text', usetex=True)\n",
    "    fig,ax1 = plt.subplots()\n",
    "    if exact == 1:\n",
    "        ax1.plot(Xi, K_exact, 'bv', markersize = marker_size, label ='Exact gain')\n",
    "    if rkhs_N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_N, 'r*', markersize = marker_size, label = 'RKHS approx. N')\n",
    "    if rkhs_2N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_2N, 'cs', markersize = marker_size, label = 'RKHS approx. 2N')\n",
    "    if coif == 1:\n",
    "        ax1.plot(Xi, K_coif, 'g.', markersize = marker_size, label ='Markov kernel approx.')\n",
    "    if om == 1:\n",
    "        ax1.plot(Xi, K_om, 'm*', markersize = marker_size, label = 'RKHS OM')\n",
    "    if coif_old == 1:\n",
    "        ax1.plot(Xi, K_coif_old, 'y.', markersize = marker_size, label ='Old Markov kernel')\n",
    "    ax2 =ax1.twinx()\n",
    "    ax2.plot(np.arange(-2,2,0.01), p_vec(np.arange(-2,2,0.01)),'k.-', markersize =1, label = r'$\\rho(x)$')\n",
    "    ax2.set_ylabel(r'$\\rho(x)$')\n",
    "    ax2.legend(loc=1)\n",
    "    ax1.set_xlabel('Particle Locations')\n",
    "    ax1.set_ylabel('Gain $K(x)$')\n",
    "    ax1.legend()\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_coif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rkhs_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_coif_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x:  x * (0.498677850501791*exp(-3.125*(x + 1)**2) + 0.498677850501791*exp(-3.125*(x - 1)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expf = lambda x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.quad(expf, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.quad(f,-np.inf,np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = lambda x: c*p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_vec = lambdify(x, c, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cp_vec(Xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: cp(c,p,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
