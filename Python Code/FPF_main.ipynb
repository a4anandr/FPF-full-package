{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## FPF Gain approximation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.stats import norm\n",
    "import scipy.integrate as integrate\n",
    "import math\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text',usetex = True)\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import ridge\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to generate samples from a multi-dimensional 1d- Gaussian mixture $\\times$  (d-1) independnt Gaussian distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(N, mu, sigma_b, w, dim,  sigma = None):\n",
    "    Xi  = np.zeros((N,dim))\n",
    "    for i in range(N):\n",
    "        if np.random.uniform() <= w[0]:\n",
    "            Xi[i,0] = mu[0]  + sigma_b[0] * np.random.normal()\n",
    "        else:\n",
    "            Xi[i,0]  = mu[1]  + sigma_b[1] * np.random.normal()\n",
    "        for d in range(1, dim):\n",
    "            Xi[i,d] = sigma * np.random.normal()\n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute the mean square error in gain function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(K_exact, K_approx, p):\n",
    "    N = len(K_exact)\n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    mse = (1/N) * np.linalg.norm(K_exact - K_approx)**2\n",
    "    # mse2 = np.sum(((K_exact - K_approx)**2) *np.concatenate(p_vec(Xi)))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different gain approximation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using optimal RKHS method  \n",
    "uses the extended representer theorem in - https://www.sciencedirect.com/science/article/pii/S0377042707004657?via%3Dihub\n",
    "#### Algorithm for a scalar example\n",
    "\\begin{equation}\n",
    "\\text{K}(x) = \\sum_{i=1}^N \\Bigl[ \\beta^0_i K(x^i,x) + \\beta^1_i \\frac{\\partial K} {\\partial x}(x^i,x) \\Bigr]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\beta ^* = M^{-1} b\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\\text{where,\n",
    "\t}\n",
    "\t\\quad\n",
    "\tM & := \\frac{1}{N} \\left[\\begin{array}{c} M_y\\\\ \\hline M_{xy} \\end{array}\\right] [ M_x \\,| M_{xy}] + \\lambda  \\left[\n",
    "\t\\begin{array}{c|c}\n",
    "\tM_0 & M_y \\\\\n",
    "\t\\hline\n",
    "\tM_x & M_{xy}\n",
    "\t\\end{array}\n",
    "\t\\right] \\\\\n",
    "\tb & :=  \\frac{1}{N} \\left[ \\begin{array}{c} M_0 \\\\ \\hline M_x \\end{array}\\right] \\tilde{c}\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{aligned}\n",
    "M_0(i,j) &:= K(x^i,x^j)\n",
    "\\quad\n",
    "& M_x(i,j) &:= \\frac{\\partial K}{\\partial x}(x^i,x^j)\n",
    "\\\\\n",
    "M_y(i,j) &:= \\frac{\\partial K}{\\partial y}(x^i,x^j)\n",
    "\\quad\n",
    "& M_{xy}(i,j) &:= \\frac{\\partial^2 K}{\\partial x \\partial y}(x^i,x^j).\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_2N(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    K = np.zeros((N,dim))\n",
    "    Ker_x = np.array(np.zeros((N,N,dim)))\n",
    "    Ker_xy = np.array(np.zeros((N,N,dim)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j,:] = -(Xi[i,:]-Xi[j,:]) * Ker[i,j] / (2 * epsilon)\n",
    "            Ker_xy[i,j,:] = -(((Xi[i,:] - Xi[j,:])**2) / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon) # Negative of the second Gaussian derivative, as this is K_xy and not K_x2\n",
    "    \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    # Constructing block matrices for future use\n",
    "    # K_big      = [ Ker Ker_x ; Ker_x' Ker_x_y];\n",
    "    # K_thin_yxy = [ Ker_x ; Ker_x_y]; \n",
    "    # K_thin_x   = [ Ker ; Ker_x'];\n",
    "    K_big      = np.concatenate((np.concatenate((Ker,np.transpose(np.reshape(Ker_x,(N,N)))),axis = 1), np.concatenate((np.reshape(Ker_x,(N,N)), np.reshape(Ker_xy,(N,N))),axis =1)))\n",
    "    K_thin_yxy = np.concatenate((np.transpose(np.reshape(Ker_x,(N,N))), np.reshape(Ker_xy,(N,N))))\n",
    "    # K_thin_xxy = np.concatenate((Ker_x,Ker_xy), axis = 1)\n",
    "    K_thin_x   = np.concatenate((Ker, np.reshape(Ker_x,(N,N))))\n",
    "    \n",
    "    # b used in the extended representer theorem algorithm - searching over all of the Hilbert space H\n",
    "    b_2N        = (1/N) * np.dot(K_thin_x, Y)\n",
    "    M_2N        = Lambda * K_big + (1/N) * np.matmul(K_thin_yxy, np.transpose(K_thin_yxy))\n",
    "    beta_2N     = np.linalg.solve(M_2N, b_2N)   \n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i,:] = K[i,:] + beta_2N[j] * Ker_x[i,j,:] + beta_2N[N+j] * Ker_xy[i,j,:]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,0],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,0], 'b*')\n",
    "        plt.plot(Xi, Ker_xy[:,0],'k*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_dN(Xi, C, epsilon, Lambda, diag = 1):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    K = np.zeros((N,dim))\n",
    "    Ker_x  = np.array(np.zeros((N,N,dim)))\n",
    "    Ker_xy = np.array(np.zeros((N,N, dim+1, dim+1)))\n",
    "    # Ker_xy = np.array(np.zeros((N,N, dim, dim)))\n",
    "    \n",
    "    K_big  = np.array(np.zeros(((dim+1)*N, (dim+1)*N)))\n",
    "    K_thin_x =np.array(np.zeros(((dim+1)*N, N)))\n",
    "    K_thin_xy = np.array(np.zeros(((dim+1)*N, dim * N)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j,:] = -(Xi[i,:]-Xi[j,:]) * Ker[i,j] / (2 * epsilon)\n",
    "            # Ker_x2[i,j,:] = -(((Xi[i,:] - Xi[j,:])**2)  / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon) # Negative of the second Gaussian derivative, as this is K_xy and not K_x2\n",
    "    \n",
    "    for d_i in range(dim + 1):\n",
    "        for d_j in range(dim + 1):\n",
    "            if d_i == 0:\n",
    "                if d_j == 0:\n",
    "                    K_big[d_i * N : (d_i + 1) *N, d_j * N : (d_j +1) * N ] = Ker\n",
    "                else:\n",
    "                    K_big[d_i * N : (d_i + 1) *N, d_j * N : (d_j +1) * N ] = np.transpose(Ker_x[:,:,d_j-1])\n",
    "            elif d_j == 0:\n",
    "                K_big[d_i * N : (d_i + 1) *N, d_j * N : (d_j +1) * N ] = Ker_x[:,:,d_i-1]\n",
    "            elif d_i == d_j:\n",
    "                for i in range(N):\n",
    "                    for j in range(N):\n",
    "                        Ker_xy[i,j, d_i, d_j] = -(((Xi[i,d_i-1] - Xi[j,d_i-1])**2)  / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon) \n",
    "                K_big[d_i * N : (d_i + 1) *N, d_j * N : (d_j +1) * N ] = Ker_xy[:,:,d_i, d_j]\n",
    "            else:\n",
    "                for i in range(N):\n",
    "                    for j in range(N):\n",
    "                        Ker_xy[i,j, d_i, d_j] = -((Xi[i,d_i-1] - Xi[j,d_i-1])* (Xi[i,d_j-1] - Xi[j,d_j-1])) / (2 * epsilon) * Ker[i,j] / (2 * epsilon) # Negative of the second Gaussian derivative, as this is K_xy and not K_x2        \n",
    "                K_big[d_i * N : (d_i + 1) *N, d_j * N : (d_j +1) * N ] = Ker_xy[:,:,d_i, d_j]\n",
    "            \n",
    "    for d_i in range(dim + 1):\n",
    "        if d_i == 0:\n",
    "            K_thin_x[d_i *N :(d_i+1)*N,: ] = Ker\n",
    "        else:\n",
    "            K_thin_x[d_i *N :(d_i+1)*N,: ] = Ker_x[:,:,d_i-1]\n",
    "            \n",
    "    for d_i in range(dim+1):\n",
    "        for d_j in range(dim):\n",
    "            if d_i == 0:\n",
    "                K_thin_xy[d_i * N :(d_i+1)*N, d_j * N : (d_j+1) *N] = np.transpose(Ker_x[:,:,d_j])\n",
    "            else:\n",
    "                K_thin_xy[d_i * N :(d_i+1)*N, d_j * N :(d_j+1) *N] = Ker_xy[:,:,d_i,d_j+1]\n",
    "    \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    # b used in the extended representer theorem algorithm - searching over all of the Hilbert space H\n",
    "    b_dN        = (1/N) * np.dot(K_thin_x, Y)\n",
    "    M_dN        = Lambda * K_big + (1/N) * np.matmul(K_thin_xy, np.transpose(K_thin_xy))\n",
    "    beta_dN     = np.linalg.solve(M_dN, b_dN)   \n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i,:] = K[i,:] + beta_dN[j] * Ker_x[i,j,:] \n",
    "            for d_i in range(dim):\n",
    "                K[i,:] = K[i,:] + beta_dN[(d_i + 1) *N + j] * Ker_xy[i,j,(d_i+1),1:]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi[:,0], Ker[:,1],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,1,0], 'b*')\n",
    "#         plt.plot(Xi, Ker_xy[:,1,1,1],'k*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 4.514889735999532\n"
     ]
    }
   ],
   "source": [
    "K_rkhs_2N = gain_rkhs_2N(Xi, C, eps_rkhs_2N, Lambda_rkhs_2N, diag = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken 3.5838528390004285\n"
     ]
    }
   ],
   "source": [
    "K_rkhs_dN = gain_rkhs_dN(Xi, C, eps_rkhs_dN, Lambda_rkhs_dN, diag =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Xi, K_rkhs_2N, 'r*')\n",
    "plt.plot(Xi, K_rkhs_dN, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using subspace RKHS method  \n",
    "uses normal representer theorem, obtains optimal solution on a subspace of RKHS.\n",
    "#### Algorithm\n",
    "\\begin{equation}\n",
    "\\text{K}(x) = \\sum_{i=1}^N \\beta^*_i \\frac{\\partial K}{\\partial x} (x^i,x)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\beta  := M^{-1} b   \\,,\n",
    "\\end{equation}\n",
    "where $ M := N^{-1} M_y M_x + \\lambda M_0$ and $ b := N^{-1} M_0 \\, \\tilde{c}  $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_N(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    K = np.zeros((N,dim))\n",
    "    Ker_x = np.array(np.zeros((N,N,dim)))\n",
    "    Ker_x_sum = np.zeros((N,N))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j,:] = -(Xi[i,:]-Xi[j,:]) * Ker[i,j] / (2 * epsilon)\n",
    "    \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    b_N = (1/ N) * np.dot(Ker,Y)\n",
    "    for d in np.arange(dim):\n",
    "        Ker_x_sum+= np.matmul(Ker_x[:,:,d], Ker_x[:,:,d].transpose())\n",
    "    M_N = Lambda * Ker + (1/ N) * Ker_x_sum\n",
    "    beta_N = np.linalg.solve(M_N,b_N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i,:] = K[i,:] + beta_N[j] * Ker_x[i,j,:]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,100],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,100,:], 'b*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute the exact FPF gain by numerical integration\n",
    "#### Algorithm\n",
    "\\begin{equation} \n",
    "\\text{K}(x) =  - \\frac{1}{p(x)} \\int_{-\\infty}^{x} (c(y) - \\hat{c}) p(y) dy\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_exact(Xi, c, p):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    integral = np.zeros(N)\n",
    "    \n",
    "    step = 0.01\n",
    "    xmax = max(mu) + 10\n",
    "    \n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    c_vec = lambdify(x, c, 'numpy')\n",
    "    cp    = lambdify(x, c*p, 'numpy')\n",
    "    c_hat = integrate.quad(cp, -np.inf, np.inf)[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        integral[i] = 0\n",
    "        for xj in np.arange(Xi[i], xmax + 10,  step):\n",
    "            integral[i] = integral[i] + p_vec(xj) * ( c_vec(xj) - c_hat) * step\n",
    "        K[i] = integral[i]/ p_vec(Xi[i])\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using scipy.integrate.quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_num_integrate(Xi, c, p):\n",
    "    start = timer()\n",
    "    \n",
    "    N = len(Xi)\n",
    "    K = np.zeros(N)\n",
    "    integral = np.zeros(N)\n",
    "     \n",
    "    if Xi.shape[1] == 1:\n",
    "        p_x = lambdify(x, p, 'numpy')\n",
    "        cp_x  = lambdify(x, c*p, 'numpy')\n",
    "        c_hat = integrate.quad(cp_x, -np.inf, np.inf)[0]\n",
    "        integrand_x = lambdify(x, p * (c - c_hat) , 'numpy')\n",
    "        integrand = lambda x: integrand_x(x)\n",
    "    else:\n",
    "        p_x = lambdify(x[0], p, 'numpy')\n",
    "        cp_x  = lambdify(x[0], c*p, 'numpy')\n",
    "        c_hat = integrate.quad(cp_x, -np.inf, np.inf)[0]\n",
    "        integrand_x = lambdify(x[0], p * (c - c_hat) , 'numpy')\n",
    "        integrand = lambda x: integrand_x(x)\n",
    "   \n",
    "    for i in range(N):\n",
    "        if Xi.shape[1] == 1:\n",
    "            integral[i] = integrate.quad( integrand, -np.inf, Xi[i])[0]\n",
    "            K[i] = - integral[i]/ p_x(Xi[i])\n",
    "        else:\n",
    "            integral[i] = integrate.quad( integrand, -np.inf, Xi[i,0])[0]\n",
    "            K[i] = - integral[i]/ p_x(Xi[i,0])\n",
    "    # K = np.reshape(K,(N,1))\n",
    "    \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using Markov kernel approx. method -\n",
    "Based on the Markov semigroup approximation method in https://arxiv.org/pdf/1902.07263.pdf\n",
    "#### Algorithm  \n",
    "1.Calculate $g_{ij} = \\exp(-|X^i - X^j|^2/ 4\\epsilon)$ for $i,j = 1$ to $N$  \n",
    "2.Calculate $k_{ij} = \\frac{g_{ij}}{\\sqrt{\\sum_l g_{il}}\\sqrt{\\sum_l g_{jl}}}$  \n",
    "3.Calculate $d_i = \\sum_j k_{ij}$  \n",
    "4.Calculate $\\text{T}_{ij} = \\frac{k_{ij}}{d_i}$  \n",
    "5.Calculate $\\pi_i = \\frac{d_i}{\\sum_j d_j}$  \n",
    "6.Calculate $ \\hat{h} = \\sum_{i = 1}^N \\pi_i h(X^i)$  \n",
    "7.Until convergence, $\\Phi_i = \\sum_{j=1}^N \\text{T}_{ij} \\Phi_j + \\epsilon (h - \\hat{h})$  \n",
    "8.Calculate $r_i = \\Phi_i + \\epsilon h_i$  \n",
    "9.Calculate $s_{ij} = \\frac{1}{2\\epsilon} \\text{T}_{ij} (r_j - \\sum_{k=1}^N \\text{T}_{ik} r_k)$  \n",
    "10.Calulate $\\text{K}_i  = \\sum_j s_{ij} X^j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_coif(Xi, C, epsilon, Phi, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    k = np.zeros((N,N))\n",
    "    K = np.zeros((N,dim))\n",
    "    d = np.zeros(N)\n",
    "    T = np.zeros((N,N))\n",
    "    Phi = np.zeros(N)\n",
    "    sum_term = np.zeros((N,dim))\n",
    "    max_diff = 1\n",
    "    \n",
    "    No_iterations = 50000\n",
    "    iterations = 1\n",
    "    \n",
    "    g = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            k[i,j] = g[i,j] / (np.sqrt( (1/N) * sum(g[i,:])) * np.sqrt( (1/N)* sum(g[j,:])))\n",
    "        d[i] = np.sum(k[i,:])\n",
    "        T[i,:] = np.divide(k[i,:], np.sum(k[i,:]))\n",
    "    pi = np.divide(d, np.sum(d))\n",
    "    C_hat = np.dot(pi, C)\n",
    "                      \n",
    "    while((max_diff > 1e-2) & ( iterations < No_iterations )):\n",
    "        Phi_new = np.matmul(T,Phi) + (epsilon * np.concatenate(C - C_hat)).transpose() \n",
    "        max_diff = max(Phi_new - Phi) - min(Phi_new - Phi)\n",
    "        Phi  = Phi_new\n",
    "        iterations += 1\n",
    "    \n",
    "    r = Phi + epsilon * np.concatenate(C)\n",
    "    for i in range(N):\n",
    "        sum_term[i] = np.dot( T[i,:], r)\n",
    "        K[i,:] = np.zeros(dim)\n",
    "        for j in range(N):\n",
    "            K[i,:] = K[i,:] + (1/ (2 * epsilon)) * T[i,j] * (r[j] - sum_term[i]) * Xi[j,:]                                  \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, g[1,:], 'r*')\n",
    "        plt.show()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly older version of Markov kernel approximation - from https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7799105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_coif_old(Xi, C, epsilon, Phi, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    k = np.zeros((N,N))\n",
    "    K = np.zeros((N,dim))\n",
    "    d = np.zeros(N)\n",
    "    T = np.zeros((N,N))\n",
    "    Phi = np.zeros(N)\n",
    "    sum_term = np.zeros((N,dim))\n",
    "    max_diff = 1\n",
    "    \n",
    "    No_iterations = 50000\n",
    "    iterations = 1\n",
    "    \n",
    "    g = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            k[i,j] = g[i,j] / (np.sqrt( (1/N) * sum(g[i,:])) * np.sqrt( (1/N)* sum(g[j,:])))\n",
    "        d[i] = np.sum(k[i,:])\n",
    "        T[i,:] = np.divide(k[i,:], np.sum(k[i,:]))\n",
    "                      \n",
    "    while((max_diff > 1e-2) & ( iterations < No_iterations )):\n",
    "        Phi_new = np.matmul(T,Phi) + (epsilon * np.concatenate(C)).transpose() \n",
    "        max_diff = max(Phi_new - Phi) - min(Phi_new - Phi)\n",
    "        Phi  = Phi_new\n",
    "        iterations += 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        sum_term[i,:] = np.dot( T[i,:], Xi)\n",
    "        K[i,:] = np.zeros(dim)\n",
    "        for j in range(N):\n",
    "            K[i,:] = K[i,:] + (1/ (2 * epsilon)) * T[i,j] * Phi[j,] * (Xi[j,:] - sum_term[i,:])   \n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, g[1,:], 'r*')\n",
    "        plt.show()\n",
    "    \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to approximate FPF gain using RKHS OM method - Adds a Lagrangian parameter $\\mu$ to make use of the constant gain approximation\n",
    "#### Algorithm\n",
    "$\\beta^*$ obtained by solving the set of linear equations\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "0  &=  2 \\Bigl(  \\frac{1}{N}  \\sum_{k=1}^d M_{x_k}^T M_{x_k}   +  \\lambda M_0 \\Bigr) \\beta ^* + \\frac{ \\kappa \\mu ^*}{N}+  \\frac{2}{N} \\Bigl( \\kappa \\text{K}^*  -   M_0 \\tilde{c} \\Bigr)  \\\\\n",
    "0  & = \\kappa^{T} \\beta^*\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rkhs_om(Xi, C, epsilon, Lambda, diag = 0):\n",
    "    start = timer()\n",
    "    \n",
    "    N,dim = Xi.shape\n",
    "    K = np.zeros((N,dim))\n",
    "    Ker_x = np.array(np.zeros((N,N,dim)))\n",
    "    # Ker_xy = np.array(np.zeros((N,N)))\n",
    "    \n",
    "    Ker = np.exp(- squareform(pdist(Xi,'euclidean'))**2/ (4 * epsilon))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            Ker_x[i,j,:] = -(Xi[i,:]-Xi[j,:]) * Ker[i,j] / (2 * epsilon)\n",
    "            # Ker_xy[i,j] = (((Xi[i] - Xi[j])**2) / (2 * epsilon) -1) * Ker[i,j] / (2 * epsilon)\n",
    "    Ker_x_ones = np.dot(np.ones((1,N)), Ker_x)\n",
    "   \n",
    "    eta = np.mean(C)\n",
    "    Y = (C -eta)\n",
    "    \n",
    "    K_hat = np.mean(Y * Xi)\n",
    "    \n",
    "    b_m = (1/ N) * np.dot(Ker,Y) - (1/ N) * np.transpose(Ker_x_ones) * K_hat \n",
    "    b_m = np.append(b_m, np.zeros((1,1)))\n",
    "    \n",
    "    M_m = Lambda * Ker + (1 / N) * np.matmul(Ker_x, Ker_x.transpose()) \n",
    "    M_m = np.vstack((M_m, (1/N) * Ker_x_ones))\n",
    "    M_m = np.hstack((M_m, np.transpose(np.append(Ker_x_ones,np.zeros((1,1)))).reshape(len(M_m),1)))\n",
    "    \n",
    "    beta_m = np.linalg.solve(M_m,b_m)\n",
    "    \n",
    "    K.fill(K_hat)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i] = K[i] + beta_m[j] * Ker_x[i,j]\n",
    "            \n",
    "    if diag == 1:\n",
    "        plt.figure()\n",
    "        plt.plot(Xi, Ker[:,0],'r*')\n",
    "        plt.plot(Xi, Ker_x[:,0], 'b*')\n",
    "        plt.plot(Xi, Ker_xy[:,0],'k*')\n",
    "        plt.show()\n",
    "            \n",
    "    end = timer()\n",
    "    print('Time taken' , end - start)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code\n",
    "#### Defines a 2-component Gaussian mixture density $p$, generates samples from $p$ and passes to the various gain approximation functions, that return the gain vectors. If exact flag is set, the exact gain is computed via numerical integration and is used to compute mean-squared error of each of the approximations.  \n",
    "Can change parameters like - no. of independent trials, no. of particles $N$, dimensionality of the system $d$ etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "Time taken 0.37308159799999885\n",
      "Time taken 4.887675950000016\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (500,1) (1000,500) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fc4397aa8054>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mK_rkhs_2N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain_rkhs_2N\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_rkhs_2N\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda_rkhs_2N\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexact\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mmse_rkhs_2N\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_rkhs_2N\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrkhs_dN\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ce66a394b293>\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(K_exact, K_approx, p)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mp_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlambdify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mK_approx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# mse2 = np.sum(((K_exact - K_approx)**2) *np.concatenate(p_vec(Xi)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2357\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2359\u001b[1;33m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2360\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (500,1) (1000,500) "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Flags to be set to choose which methods to compare\n",
    "    exact  = 1      # Computes the exact gain and plots \n",
    "    coif   = 0      # Computes gain using Coifman kernel method\n",
    "    rkhs_N = 0      # Computes gain using subspace of RKHS\n",
    "    rkhs_2N= 1      # Computes optimal gain using RKHS \n",
    "    rkhs_dN= 1      # Computes optimal gain using RKHS for any arbitrary dimension d\n",
    "    om     = 0      # Computes gain using RKHS enforcing constant gain constraint\n",
    "    memory = 0      # Computes gain using RKHS with a memory parameter for previous gain\n",
    "    om_mem = 0      # Computes gain using const gain approx and a memory parameter for previous gain\n",
    "    \n",
    "    coif_old = 0   # Computes old implementation of Coifman kernel approx. \n",
    "    const  = 0      # Computes the constant gain approximation\n",
    "    kalman = 0      # Runs Kalman Filter for comparison\n",
    "    sis    = 0      # Runs Sequential Importance Sampling Particle Filter \n",
    "\n",
    "    # Run parameters\n",
    "    No_runs = 1\n",
    "    \n",
    "    # FPF parameters - No. of particles\n",
    "    N = 500\n",
    "    \n",
    "    # System parameters\n",
    "    x = Symbol('x')\n",
    "    dim = 1     # dimension of the system\n",
    "    c = x       # Observation function\n",
    "    c_x = lambdify(x, c, 'numpy')\n",
    "        \n",
    "    # Parameters of the prior density p(0) - 2 component Gaussian mixture density\n",
    "    m = 2      # No of components in the Gaussian mixture\n",
    "    sigma = [0.4472, 0.4472]\n",
    "    mu  = [-1, 1]\n",
    "    w   = [0.5, 0.5]\n",
    "    w[-1] = 1 - sum(w[:-1])\n",
    "    p = 0\n",
    "    mu_eq = 0  # Equivalent mean of the density p\n",
    "    for m in range(len(w)):\n",
    "        p = p + w[m] * (1/ np.sqrt(2 * math.pi * sigma[m]**2))* exp(-(x - mu[m])**2/ (2* sigma[m]**2))\n",
    "    p_vec = lambdify(x, p, 'numpy')\n",
    "    \n",
    "    mse_coif = np.zeros(No_runs)\n",
    "    mse_rkhs_N = np.zeros(No_runs)\n",
    "    mse_rkhs_2N = np.zeros(No_runs)\n",
    "    mse_rkhs_dN = np.zeros(No_runs)\n",
    "    mse_om   = np.zeros(No_runs)\n",
    "    mse_coif_old = np.zeros(No_runs)\n",
    "    for run in range(No_runs):\n",
    "        clear_output()\n",
    "        print('Run ',run)\n",
    "        Xi  = get_samples(N, mu, sigma, w, dim)\n",
    "        if dim == 1:\n",
    "            Xi = np.sort(Xi,kind = 'mergesort')\n",
    "        C   = c_x(Xi)\n",
    "# To check consistency with Matlab code output - using the same samples \n",
    "#         Xi = np.loadtxt('Xi.txt')\n",
    "#         Xi = np.sort(Xi,kind = 'mergesort')\n",
    "#         Xi = np.reshape(Xi,(-1,1))\n",
    "#         plt.figure()\n",
    "#         sns.distplot(Xi)\n",
    "#         plt.show()\n",
    "\n",
    "        if exact == 1:\n",
    "            # c_hat = mu_eq   # True only for c = x, linear function          \n",
    "            # K_exact  = gain_exact(Xi, c, p)   # Manual numerical integration\n",
    "            K_exact =  np.zeros((N,dim))\n",
    "            K_exact[:,0] =  gain_num_integrate(Xi, c, p)  # Uses scipy.integrate function\n",
    "\n",
    "        if coif ==1:\n",
    "            eps_coif = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif = gain_coif(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif[run] = mean_squared_error(K_exact, K_coif, p)\n",
    "\n",
    "        if rkhs_N == 1:\n",
    "            eps_rkhs_N = 0.1\n",
    "            Lambda_rkhs_N = 1e-3\n",
    "            K_rkhs_N = gain_rkhs_N(Xi, C, eps_rkhs_N, Lambda_rkhs_N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_N[run] = mean_squared_error(K_exact, K_rkhs_N, p)\n",
    "\n",
    "        if rkhs_2N == 1:\n",
    "            eps_rkhs_2N = 0.1\n",
    "            Lambda_rkhs_2N = 1e-3\n",
    "            K_rkhs_2N = gain_rkhs_2N(Xi, C, eps_rkhs_2N, Lambda_rkhs_2N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_2N[run] = mean_squared_error(K_exact, K_rkhs_2N, p)\n",
    "                \n",
    "        if rkhs_dN == 1:\n",
    "            eps_rkhs_dN = 0.1\n",
    "            Lambda_rkhs_dN = 1e-3\n",
    "            K_rkhs_dN = gain_rkhs_dN(Xi, C, eps_rkhs_dN, Lambda_rkhs_dN, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_dN[run] = mean_squared_error(K_exact, K_rkhs_dN, p)\n",
    "\n",
    "        if om == 1:\n",
    "            eps_om = 0.1\n",
    "            Lambda_om = 1e-3\n",
    "            K_om = gain_rkhs_om(Xi, C, eps_om, Lambda_om, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_om[run] = mean_squared_error(K_exact, K_om, p)\n",
    "                \n",
    "        if coif_old == 1:\n",
    "            eps_coif_old = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif_old = gain_coif_old(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif_old[run] = mean_squared_error(K_exact, K_coif_old, p)\n",
    "         \n",
    "    print('\\n')\n",
    "    if exact == 1 & coif == 1:\n",
    "        print('MSE for Markov kernel approx', np.mean(mse_coif))\n",
    "    if exact == 1 & rkhs_N == 1:\n",
    "        print('MSE for RKHS N', np.mean(mse_rkhs_N))\n",
    "    if exact == 1 & rkhs_2N == 1:\n",
    "        print('MSE for RKHS 2N', np.mean(mse_rkhs_2N))\n",
    "    if exact == 1 & rkhs_dN == 1:\n",
    "        print('MSE for RKHS dN', np.mean(mse_rkhs_dN))\n",
    "    if exact == 1 & om == 1:\n",
    "        print('MSE for RKHS OM', np.mean(mse_om))\n",
    "    if exact == 1 & coif_old == 1:\n",
    "        print('MSE for old Markov kernel', np.mean(mse_coif_old))\n",
    "    \n",
    "    ### Displaying the plots\n",
    "    marker_size  = 3\n",
    "    plt.rc('text', usetex=True)\n",
    "    fig,ax1 = plt.subplots()\n",
    "    if exact == 1:\n",
    "        ax1.plot(Xi, K_exact, 'b.', markersize = marker_size, label ='Exact gain')\n",
    "        # ax1.plot(Xi, K_num_int, 'k^', markersize = marker_size, label ='Num int. gain')\n",
    "    if rkhs_N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_N, 'r.', markersize = marker_size, label = 'RKHS approx. N')\n",
    "    if rkhs_2N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_2N, 'c.', markersize = marker_size, label = 'RKHS approx. 2N')\n",
    "    if rkhs_dN == 1:\n",
    "        ax1.plot(Xi, K_rkhs_dN, 'm.', markersize = marker_size, label = 'RKHS approx. dN')\n",
    "    if coif == 1:\n",
    "        ax1.plot(Xi, K_coif, 'g.', markersize = marker_size, label ='Markov kernel approx.')\n",
    "    if om == 1:\n",
    "        ax1.plot(Xi, K_om, 'm.', markersize = marker_size, label = 'RKHS OM')\n",
    "    if coif_old == 1:\n",
    "        ax1.plot(Xi, K_coif_old, 'y.', markersize = marker_size, label ='Old Markov kernel')\n",
    "    ax2 =ax1.twinx()\n",
    "    ax2.plot(np.arange(-2,2,0.01), p_vec(np.arange(-2,2,0.01)),'k.-', markersize =1, label = r'$\\rho(x)$')\n",
    "    ax2.set_ylabel(r'$\\rho(x)$')\n",
    "    ax2.legend(loc=1)\n",
    "    ax1.set_xlabel('Particle Locations')\n",
    "    ax1.set_ylabel('Gain $K(x)$')\n",
    "    ax1.legend()\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the histogram of the mse from the various trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(mse_coif,label='Coifman')\n",
    "sns.distplot(mse_rkhs_N, label = 'RKHS N')\n",
    "sns.distplot(mse_coif_old, label = 'Coifman old')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-dimensional example in section 5.1  - https://arxiv.org/pdf/1902.07263.pdf  \n",
    "\\begin{equation}\n",
    "\\rho(x) = \\rho_B(x_1) \\prod_{n=2}^d \\rho_G(x_n), \\qquad \\text{for } x = (x_1,x_2, \\cdots, x_d) \\in \\mathbb{R}^d \n",
    "\\end{equation}\n",
    "Here, $\\rho_B$ is $\\frac{1}{2} \\mathcal{N}(-1, \\sigma^2) + \\frac{1}{2}\\mathcal{N}(+1,\\sigma^2)$ is bimodal distribution  \n",
    "$\\rho_G$ is Gaussian distribution, $\\mathcal{N}(0,\\sigma^2)$  \n",
    "Observation function, $h(x) = x_1$  \n",
    "Exact gain function, $\\text{K}_{\\text{exact}}(x) = (\\text{K}_{\\text{exact}}(x_1), 0, \\cdots,0)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run  0\n",
      "Time taken 0.1463027190000048\n",
      "Time taken 0.83146979899999\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (200,2) (600,400) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c16cd3a1590a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mK_rkhs_dN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain_rkhs_dN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_rkhs_dN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda_rkhs_dN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mexact\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[0mmse_rkhs_dN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK_rkhs_dN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mom\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ce66a394b293>\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(K_exact, K_approx, p)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mp_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlambdify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK_exact\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mK_approx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# mse2 = np.sum(((K_exact - K_approx)**2) *np.concatenate(p_vec(Xi)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2357\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2359\u001b[1;33m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2360\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (200,2) (600,400) "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Flags to be set to choose which methods to compare\n",
    "    exact  = 1      # Computes the exact gain and plots \n",
    "    coif   = 0      # Computes gain using Coifman kernel method\n",
    "    rkhs_N = 0      # Computes gain using subspace of RKHS\n",
    "    rkhs_dN= 1      # Computes optimal gain using RKHS \n",
    "    om     = 0      # Computes gain using RKHS enforcing constant gain constraint\n",
    "    memory = 0      # Computes gain using RKHS with a memory parameter for previous gain\n",
    "    om_mem = 0      # Computes gain using const gain approx and a memory parameter for previous gain\n",
    "    \n",
    "    coif_old = 0    # Computes old implementation of Coifman kernel approx. \n",
    "    const  = 0      # Computes the constant gain approximation\n",
    "    kalman = 0      # Runs Kalman Filter for comparison\n",
    "    sis    = 0      # Runs Sequential Importance Sampling Particle Filter \n",
    "\n",
    "    # Run parameters\n",
    "    No_runs = 1\n",
    "    \n",
    "    # FPF parameters - No. of particles\n",
    "    N = 200\n",
    "    \n",
    "    # System parameters\n",
    "    dim = 2     # dimension of the system\n",
    "    x = symbols('x0:%d'%dim)\n",
    "    c = x[0]       # Observation function\n",
    "    # c_x = lambdify(x, c, 'numpy')\n",
    "    c_x = lambdify(x[0], c, 'numpy')\n",
    "        \n",
    "    # Parameters of the prior density \\rho_B - 2 component Gaussian mixture density\n",
    "    m = 2      # No of components in the Gaussian mixture\n",
    "    sigma_b = [0.4472, 0.4472]   # Gives \\sigma^2 = 0.2\n",
    "    mu_b  = [-1, 1]\n",
    "    w_b   = [0.5, 0.5]\n",
    "    w_b[-1] = 1 - sum(w_b[:-1])\n",
    "    p_b = 0\n",
    "    for m in range(len(w_b)):\n",
    "        p_b = p_b + w_b[m] * (1/ np.sqrt(2 * math.pi * sigma_b[m]**2))* exp(-(x[0] - mu_b[m])**2/ (2* sigma_b[m]**2))\n",
    "    p_b_x = lambdify(x[0], p_b, 'numpy')\n",
    "    sigma = 0.4472  # Chosen so that \\sigma^2 = 0.2 as in the reference\n",
    "    p = p_b\n",
    "    for d in np.arange(1,dim):\n",
    "        p_g = exp(-x[d])**2/ (2 * sigma**2)\n",
    "        p*= p_g\n",
    "    \n",
    "    \n",
    "    mse_coif = np.zeros(No_runs)\n",
    "    mse_rkhs_N = np.zeros(No_runs)\n",
    "    mse_rkhs_dN = np.zeros(No_runs)\n",
    "    mse_om   = np.zeros(No_runs)\n",
    "    mse_coif_old = np.zeros(No_runs)\n",
    "    for run in range(No_runs):\n",
    "        clear_output()\n",
    "        print('Run ',run)\n",
    "        Xi  = get_samples(N, mu_b, sigma_b, w_b, dim, sigma)\n",
    "        get_samples\n",
    "        if dim == 1:\n",
    "            Xi = np.sort(Xi,kind = 'mergesort')\n",
    "        C = np.reshape(c_x(Xi[:,0]),(len(Xi),1))\n",
    "        # C   = np.reshape(c_x(Xi[:,0],Xi[:,1]),(len(Xi),1))\n",
    "        \n",
    "        if exact == 1:\n",
    "         \n",
    "            K_exact = np.zeros((N, dim))\n",
    "            K_exact[:,0]  = gain_num_integrate(Xi, c, p_b)\n",
    "\n",
    "        if coif ==1:\n",
    "            eps_coif = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif = gain_coif(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif[run] = mean_squared_error(K_exact, K_coif, p)\n",
    "\n",
    "        if rkhs_N == 1:\n",
    "            eps_rkhs_N = 0.1\n",
    "            Lambda_rkhs_N = 1e-3\n",
    "            K_rkhs_N = gain_rkhs_N(Xi, C, eps_rkhs_N, Lambda_rkhs_N, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_N[run] = mean_squared_error(K_exact, K_rkhs_N, p)\n",
    "\n",
    "        if rkhs_dN == 1:\n",
    "            eps_rkhs_dN = 0.1\n",
    "            Lambda_rkhs_dN = 1e-3\n",
    "            K_rkhs_dN = gain_rkhs_dN(Xi, C, eps_rkhs_dN, Lambda_rkhs_dN, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_rkhs_dN[run] = mean_squared_error(K_exact, K_rkhs_dN, p)\n",
    "\n",
    "        if om == 1:\n",
    "            eps_om = 0.1\n",
    "            Lambda_om = 1e-3\n",
    "            K_om = gain_rkhs_om(Xi, C, eps_om, Lambda_om, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_om[run] = mean_squared_error(K_exact, K_om, p)\n",
    "                \n",
    "        if coif_old == 1:\n",
    "            eps_coif_old = 0.1\n",
    "            Phi = np.zeros(N)\n",
    "            K_coif_old = gain_coif_old(Xi, C, eps_coif, Phi, diag = 0)\n",
    "            if exact == 1:\n",
    "                mse_coif_old[run] = mean_squared_error(K_exact, K_coif_old, p)\n",
    "         \n",
    "    print('\\n')\n",
    "    if exact == 1 & coif == 1:\n",
    "        print('MSE for Markov kernel approx', np.mean(mse_coif))\n",
    "    if exact == 1 & rkhs_N == 1:\n",
    "        print('MSE for RKHS N', np.mean(mse_rkhs_N))\n",
    "    if exact == 1 & rkhs_dN == 1:\n",
    "        print('MSE for RKHS dN', np.mean(mse_rkhs_dN))\n",
    "    if exact == 1 & om == 1:\n",
    "        print('MSE for RKHS OM', np.mean(mse_om))\n",
    "    if exact == 1 & coif_old == 1:\n",
    "        print('MSE for old Markov kernel', np.mean(mse_coif_old))\n",
    "    \n",
    "    ### Displaying the plots\n",
    "    marker_size  = 3\n",
    "    plt.rc('text', usetex=True)\n",
    "    fig,ax1 = plt.subplots()\n",
    "    if exact == 1:\n",
    "        ax1.plot(Xi, K_exact, 'bv', markersize = marker_size, label ='Exact gain')\n",
    "    if rkhs_N == 1:\n",
    "        ax1.plot(Xi, K_rkhs_N, 'r*', markersize = marker_size, label = 'RKHS approx. N')\n",
    "    if rkhs_dN == 1:\n",
    "        ax1.plot(Xi, K_rkhs_dN, 'cs', markersize = marker_size, label = 'RKHS approx. dN')\n",
    "    if coif == 1:\n",
    "        ax1.plot(Xi, K_coif, 'g.', markersize = marker_size, label ='Markov kernel approx.')\n",
    "    if om == 1:\n",
    "        ax1.plot(Xi, K_om, 'm*', markersize = marker_size, label = 'RKHS OM')\n",
    "    if coif_old == 1:\n",
    "        ax1.plot(Xi, K_coif_old, 'y.', markersize = marker_size, label ='Old Markov kernel')\n",
    "    ax2 =ax1.twinx()\n",
    "    ax2.plot(np.arange(-2,2,0.01), p_b_x(np.arange(-2,2,0.01)),'k.-', markersize =1, label = r'$\\rho(x)$')\n",
    "    ax2.set_ylabel(r'$\\rho(x)$')\n",
    "    ax2.legend(loc=1)\n",
    "    ax1.set_xlabel('Particle Locations')\n",
    "    ax1.set_ylabel('Gain $K(x)$')\n",
    "    ax1.legend()\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_rkhs_2N[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_coif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rkhs_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_coif_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the histogram of the mse from the various trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(mse_coif,label='Coifman')\n",
    "sns.distplot(mse_rkhs_N, label = 'RKHS N')\n",
    "sns.distplot(mse_coif_old, label = 'Coifman old')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x:  x * (0.498677850501791*exp(-3.125*(x + 1)**2) + 0.498677850501791*exp(-3.125*(x - 1)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expf = lambda x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.quad(expf, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrate.quad(f,-np.inf,np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = lambda x: c*p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_vec = lambdify(x, c, 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cp_vec(Xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: cp(c,p,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
